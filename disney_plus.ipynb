{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50907b1f-b87e-41fd-bcc2-f6f1c92904c9",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b844c6b-731f-4653-a435-9b67cbe99464",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "\n",
    "from pymilvus import MilvusClient\n",
    "from langchain_huggingface.embeddings import HuggingFaceEmbeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae291e8f-5ac0-4a40-adbf-5a9e1e440d24",
   "metadata": {},
   "source": [
    "# Step 1: Data Ingestion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b4e37a-8b75-41ef-be9f-874081d73cdb",
   "metadata": {},
   "source": [
    "For this notebook, we will use a public dataset found on kaggle: https://www.kaggle.com/datasets/shivamb/disney-movies-and-tv-shows. This data set is a collection of titles on the Disney+ platform. This dataset is a mix of structured data (type, release_year, listed_in, etc.) and unstructured data (title, description)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0def4293-725c-4093-9690-446026638fca",
   "metadata": {},
   "source": [
    "## 1.1 Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8be23545-79c6-4913-8c2e-bb6cf60865bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_disney_df = pd.read_csv('disney_plus_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad978789-5204-444e-948c-adfbcae8050a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>show_id</th>\n",
       "      <th>type</th>\n",
       "      <th>title</th>\n",
       "      <th>director</th>\n",
       "      <th>cast</th>\n",
       "      <th>country</th>\n",
       "      <th>date_added</th>\n",
       "      <th>release_year</th>\n",
       "      <th>rating</th>\n",
       "      <th>duration</th>\n",
       "      <th>listed_in</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>s1</td>\n",
       "      <td>Movie</td>\n",
       "      <td>Duck the Halls: A Mickey Mouse Christmas Special</td>\n",
       "      <td>Alonso Ramirez Ramos, Dave Wasson</td>\n",
       "      <td>Chris Diamantopoulos, Tony Anselmo, Tress MacN...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>November 26, 2021</td>\n",
       "      <td>2016</td>\n",
       "      <td>TV-G</td>\n",
       "      <td>23 min</td>\n",
       "      <td>Animation, Family</td>\n",
       "      <td>Join Mickey and the gang as they duck the halls!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>s2</td>\n",
       "      <td>Movie</td>\n",
       "      <td>Ernest Saves Christmas</td>\n",
       "      <td>John Cherry</td>\n",
       "      <td>Jim Varney, Noelle Parker, Douglas Seale</td>\n",
       "      <td>NaN</td>\n",
       "      <td>November 26, 2021</td>\n",
       "      <td>1988</td>\n",
       "      <td>PG</td>\n",
       "      <td>91 min</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>Santa Claus passes his magic bag to a new St. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>s3</td>\n",
       "      <td>Movie</td>\n",
       "      <td>Ice Age: A Mammoth Christmas</td>\n",
       "      <td>Karen Disher</td>\n",
       "      <td>Raymond Albert Romano, John Leguizamo, Denis L...</td>\n",
       "      <td>United States</td>\n",
       "      <td>November 26, 2021</td>\n",
       "      <td>2011</td>\n",
       "      <td>TV-G</td>\n",
       "      <td>23 min</td>\n",
       "      <td>Animation, Comedy, Family</td>\n",
       "      <td>Sid the Sloth is on Santa's naughty list.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>s4</td>\n",
       "      <td>Movie</td>\n",
       "      <td>The Queen Family Singalong</td>\n",
       "      <td>Hamish Hamilton</td>\n",
       "      <td>Darren Criss, Adam Lambert, Derek Hough, Alexa...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>November 26, 2021</td>\n",
       "      <td>2021</td>\n",
       "      <td>TV-PG</td>\n",
       "      <td>41 min</td>\n",
       "      <td>Musical</td>\n",
       "      <td>This is real life, not just fantasy!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>s5</td>\n",
       "      <td>TV Show</td>\n",
       "      <td>The Beatles: Get Back</td>\n",
       "      <td>NaN</td>\n",
       "      <td>John Lennon, Paul McCartney, George Harrison, ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>November 25, 2021</td>\n",
       "      <td>2021</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1 Season</td>\n",
       "      <td>Docuseries, Historical, Music</td>\n",
       "      <td>A three-part documentary from Peter Jackson ca...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  show_id     type                                             title  \\\n",
       "0      s1    Movie  Duck the Halls: A Mickey Mouse Christmas Special   \n",
       "1      s2    Movie                            Ernest Saves Christmas   \n",
       "2      s3    Movie                      Ice Age: A Mammoth Christmas   \n",
       "3      s4    Movie                        The Queen Family Singalong   \n",
       "4      s5  TV Show                             The Beatles: Get Back   \n",
       "\n",
       "                            director  \\\n",
       "0  Alonso Ramirez Ramos, Dave Wasson   \n",
       "1                        John Cherry   \n",
       "2                       Karen Disher   \n",
       "3                    Hamish Hamilton   \n",
       "4                                NaN   \n",
       "\n",
       "                                                cast        country  \\\n",
       "0  Chris Diamantopoulos, Tony Anselmo, Tress MacN...            NaN   \n",
       "1           Jim Varney, Noelle Parker, Douglas Seale            NaN   \n",
       "2  Raymond Albert Romano, John Leguizamo, Denis L...  United States   \n",
       "3  Darren Criss, Adam Lambert, Derek Hough, Alexa...            NaN   \n",
       "4  John Lennon, Paul McCartney, George Harrison, ...            NaN   \n",
       "\n",
       "          date_added  release_year rating  duration  \\\n",
       "0  November 26, 2021          2016   TV-G    23 min   \n",
       "1  November 26, 2021          1988     PG    91 min   \n",
       "2  November 26, 2021          2011   TV-G    23 min   \n",
       "3  November 26, 2021          2021  TV-PG    41 min   \n",
       "4  November 25, 2021          2021    NaN  1 Season   \n",
       "\n",
       "                       listed_in  \\\n",
       "0              Animation, Family   \n",
       "1                         Comedy   \n",
       "2      Animation, Comedy, Family   \n",
       "3                        Musical   \n",
       "4  Docuseries, Historical, Music   \n",
       "\n",
       "                                         description  \n",
       "0   Join Mickey and the gang as they duck the halls!  \n",
       "1  Santa Claus passes his magic bag to a new St. ...  \n",
       "2          Sid the Sloth is on Santa's naughty list.  \n",
       "3               This is real life, not just fantasy!  \n",
       "4  A three-part documentary from Peter Jackson ca...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preview the data\n",
    "raw_disney_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc76181c-a9e6-489c-81c7-f26b9a5ddca0",
   "metadata": {},
   "source": [
    "## 1.2 Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b76b6f5-9cc7-4e19-a7b5-5ab5b3e7c64b",
   "metadata": {},
   "source": [
    "Here we will do some basic exploration of the data to see if there is anything of note"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a31c00a9-c2b7-438f-8c0a-5294c4d3754d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_distinct_elements(col_series):\n",
    "    all_elems = set()\n",
    "    for elems_str in col_series:\n",
    "        if pd.isnull(elems_str):\n",
    "            continue\n",
    "        items = elems_str.split(\",\")\n",
    "        for item in items:\n",
    "            all_elems.add(item.strip())\n",
    "    return all_elems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "24f4b98d-0ca3-41c9-86e1-2a298e74d19f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1450.0\n",
       "mean        1.0\n",
       "std         0.0\n",
       "min         1.0\n",
       "25%         1.0\n",
       "50%         1.0\n",
       "75%         1.0\n",
       "max         1.0\n",
       "Name: count, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Each show_id is unique\n",
    "raw_disney_df['show_id'].value_counts().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "82090e36-3ae4-4827-a250-28a083973b5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Movie', 'TV Show'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# All of the types are \"Movie\" or \"TV Show\"\n",
    "raw_disney_df['type'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "38d58571-9b63-4a3a-b47e-c73fb72c5078",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['TV-G', 'PG', 'TV-PG', nan, 'PG-13', 'TV-14', 'G', 'TV-Y7', 'TV-Y',\n",
       "       'TV-Y7-FV'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# None of these ratings are out of the ordinary\n",
    "raw_disney_df['rating'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "21a968d8-636b-4bb4-8b08-35ef8af3f383",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Angola',\n",
       " 'Argentina',\n",
       " 'Australia',\n",
       " 'Austria',\n",
       " 'Belgium',\n",
       " 'Botswana',\n",
       " 'Brazil',\n",
       " 'Canada',\n",
       " 'China',\n",
       " 'Czech Republic',\n",
       " 'Denmark',\n",
       " 'Egypt',\n",
       " 'France',\n",
       " 'Germany',\n",
       " 'Guatemala',\n",
       " 'Hong Kong',\n",
       " 'Hungary',\n",
       " 'India',\n",
       " 'Iran',\n",
       " 'Ireland',\n",
       " 'Japan',\n",
       " 'Kazakhstan',\n",
       " 'Luxembourg',\n",
       " 'Malaysia',\n",
       " 'Mexico',\n",
       " 'Namibia',\n",
       " 'New Zealand',\n",
       " 'Norway',\n",
       " 'Pakistan',\n",
       " 'Panama',\n",
       " 'Philippines',\n",
       " 'Poland',\n",
       " 'Russia',\n",
       " 'Singapore',\n",
       " 'Slovenia',\n",
       " 'South Africa',\n",
       " 'South Korea',\n",
       " 'Spain',\n",
       " 'Sweden',\n",
       " 'Switzerland',\n",
       " 'Syria',\n",
       " 'Taiwan',\n",
       " 'Tanzania',\n",
       " 'Thailand',\n",
       " 'United Arab Emirates',\n",
       " 'United Kingdom',\n",
       " 'United States'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# All of these countries are valid\n",
    "get_distinct_elements(raw_disney_df['country'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1f7ad0ae-9e24-4cf3-82c2-6b1a4779e61f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1 Season',\n",
       " '1 min',\n",
       " '10 Seasons',\n",
       " '10 min',\n",
       " '100 min',\n",
       " '101 min',\n",
       " '102 min',\n",
       " '103 min',\n",
       " '104 min',\n",
       " '105 min',\n",
       " '106 min',\n",
       " '107 min',\n",
       " '108 min',\n",
       " '109 min',\n",
       " '11 min',\n",
       " '110 min',\n",
       " '111 min',\n",
       " '112 min',\n",
       " '113 min',\n",
       " '114 min',\n",
       " '115 min',\n",
       " '116 min',\n",
       " '117 min',\n",
       " '118 min',\n",
       " '119 min',\n",
       " '12 min',\n",
       " '120 min',\n",
       " '121 min',\n",
       " '122 min',\n",
       " '123 min',\n",
       " '124 min',\n",
       " '125 min',\n",
       " '126 min',\n",
       " '127 min',\n",
       " '128 min',\n",
       " '129 min',\n",
       " '13 min',\n",
       " '130 min',\n",
       " '131 min',\n",
       " '132 min',\n",
       " '134 min',\n",
       " '135 min',\n",
       " '136 min',\n",
       " '137 min',\n",
       " '138 min',\n",
       " '139 min',\n",
       " '14 min',\n",
       " '140 min',\n",
       " '142 min',\n",
       " '143 min',\n",
       " '144 min',\n",
       " '145 min',\n",
       " '147 min',\n",
       " '148 min',\n",
       " '15 min',\n",
       " '150 min',\n",
       " '151 min',\n",
       " '152 min',\n",
       " '154 min',\n",
       " '16 Seasons',\n",
       " '160 min',\n",
       " '162 min',\n",
       " '169 min',\n",
       " '170 min',\n",
       " '175 min',\n",
       " '18 min',\n",
       " '180 min',\n",
       " '182 min',\n",
       " '183 min',\n",
       " '19 Seasons',\n",
       " '19 min',\n",
       " '2 Seasons',\n",
       " '2 min',\n",
       " '20 min',\n",
       " '21 min',\n",
       " '22 min',\n",
       " '23 min',\n",
       " '24 min',\n",
       " '25 min',\n",
       " '26 min',\n",
       " '27 min',\n",
       " '3 Seasons',\n",
       " '3 min',\n",
       " '30 min',\n",
       " '31 min',\n",
       " '32 Seasons',\n",
       " '32 min',\n",
       " '33 min',\n",
       " '4 Seasons',\n",
       " '4 min',\n",
       " '41 min',\n",
       " '42 min',\n",
       " '43 min',\n",
       " '44 min',\n",
       " '45 min',\n",
       " '46 min',\n",
       " '47 min',\n",
       " '48 min',\n",
       " '49 min',\n",
       " '5 Seasons',\n",
       " '5 min',\n",
       " '50 min',\n",
       " '51 min',\n",
       " '52 min',\n",
       " '53 min',\n",
       " '54 min',\n",
       " '55 min',\n",
       " '56 min',\n",
       " '58 min',\n",
       " '59 min',\n",
       " '6 Seasons',\n",
       " '6 min',\n",
       " '60 min',\n",
       " '61 min',\n",
       " '62 min',\n",
       " '63 min',\n",
       " '64 min',\n",
       " '65 min',\n",
       " '66 min',\n",
       " '67 min',\n",
       " '68 min',\n",
       " '69 min',\n",
       " '7 Seasons',\n",
       " '7 min',\n",
       " '70 min',\n",
       " '71 min',\n",
       " '72 min',\n",
       " '73 min',\n",
       " '74 min',\n",
       " '75 min',\n",
       " '76 min',\n",
       " '77 min',\n",
       " '78 min',\n",
       " '79 min',\n",
       " '8 Seasons',\n",
       " '8 min',\n",
       " '80 min',\n",
       " '81 min',\n",
       " '82 min',\n",
       " '83 min',\n",
       " '84 min',\n",
       " '85 min',\n",
       " '86 min',\n",
       " '87 min',\n",
       " '88 min',\n",
       " '89 min',\n",
       " '9 Seasons',\n",
       " '9 min',\n",
       " '90 min',\n",
       " '91 min',\n",
       " '92 min',\n",
       " '93 min',\n",
       " '94 min',\n",
       " '95 min',\n",
       " '96 min',\n",
       " '97 min',\n",
       " '98 min',\n",
       " '99 min'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check to see what the options for duration are. They all end in 'min', 'Season' or 'Seasons\n",
    "get_distinct_elements(raw_disney_df['duration'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "baa6e8d8-2dd6-45a2-a82c-fad482af28e7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Action-Adventure',\n",
       " 'Animals & Nature',\n",
       " 'Animation',\n",
       " 'Anime',\n",
       " 'Anthology',\n",
       " 'Biographical',\n",
       " 'Buddy',\n",
       " 'Comedy',\n",
       " 'Coming of Age',\n",
       " 'Concert Film',\n",
       " 'Crime',\n",
       " 'Dance',\n",
       " 'Disaster',\n",
       " 'Documentary',\n",
       " 'Docuseries',\n",
       " 'Drama',\n",
       " 'Family',\n",
       " 'Fantasy',\n",
       " 'Game Show / Competition',\n",
       " 'Historical',\n",
       " 'Kids',\n",
       " 'Lifestyle',\n",
       " 'Medical',\n",
       " 'Movies',\n",
       " 'Music',\n",
       " 'Musical',\n",
       " 'Mystery',\n",
       " 'Parody',\n",
       " 'Police/Cop',\n",
       " 'Reality',\n",
       " 'Romance',\n",
       " 'Romantic Comedy',\n",
       " 'Science Fiction',\n",
       " 'Series',\n",
       " 'Soap Opera / Melodrama',\n",
       " 'Sports',\n",
       " 'Spy/Espionage',\n",
       " 'Superhero',\n",
       " 'Survival',\n",
       " 'Talk Show',\n",
       " 'Thriller',\n",
       " 'Travel',\n",
       " 'Variety',\n",
       " 'Western'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# All of these categories seem reasonable\n",
    "get_distinct_elements(raw_disney_df['listed_in'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a44f1e47-a02b-4f45-8c09-d70848216f7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "102"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The largest description is 102 characters, so not too large\n",
    "max(raw_disney_df['description'].map(lambda x: len(x) if not pd.isnull(x) else 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7861227-1673-4345-a4b9-a14fe1899759",
   "metadata": {},
   "source": [
    "## 1.3 Create Database Tables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c665e45-cede-4a07-a2cf-b5aaa1439437",
   "metadata": {},
   "source": [
    "Setting up a database properly and creating a good structure can help optimize search speed, ease of access, ensure data consistency, and maintain data connections. Setting up the correct data types can help ensure clean data and also ease an analysts job of converting the datatypes themselves. Here we will create integers for fields that need integers and also create foreign keys to make sure data dependencies are maintained. A relational database should be sufficient for stardard querying and metrics.\n",
    "\n",
    "As for other structural considerations, we split the dataset into several different tables. The benefit is that an analyst or an application may likely want to filter based on Movies or TV shows, so we will populate the two main tables 'disney_movie' and 'disney_country'. After that, due to the list-based nature of several fields (director, cast, country, listed_in), separate lookup tables are created and are linked on the show_id dimension.\n",
    "\n",
    "Another design choice was made to separate the \"duration\" field into two fields \"duration_min\" (which represents the number of minutes a movie has) and \"seasons\" to number of season for a tv show. Both of these ar converted to integers to be more useful for later analysis and trending."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b8c00e9b-24a5-4dc0-b87a-815eaf5d61e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to database\n",
    "con = sqlite3.connect(\"disney.db\")\n",
    "cur = con.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f429f5cf-2b53-48ab-9a62-15d2780800ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Movie Tables\n",
    "create_movies_stmt = \"\"\"CREATE TABLE IF NOT EXISTS disney_movie (\n",
    "\tshow_id INTEGER PRIMARY KEY,\n",
    "   \ttype TEXT DEFAULT NULL,\n",
    "\ttitle TEXT DEFAULT NULL,\n",
    "\tdate_added TEXT DEFAULT NULL,\n",
    "\trelease_year INTEGER DEFAULT NULL,\n",
    "\trating TEXT DEFAULT NULL, \n",
    "\tduration_min INTEGER DEFAULT NULL,\n",
    "\tdescription TEXT DEFAULT NULL\n",
    ") STRICT\"\"\"\n",
    "\n",
    "create_movie_country_stmt = \"\"\"CREATE TABLE IF NOT EXISTS movie_country (\n",
    "    show_id INTEGER,\n",
    "    country TEXT DEFAULT NULL,\n",
    "    FOREIGN KEY(show_id) REFERENCES disney_movie(show_id)\n",
    ") STRICT\"\"\"\n",
    "\n",
    "create_movie_directors_stmt = \"\"\"CREATE TABLE IF NOT EXISTS movie_director (\n",
    "    show_id INTEGER,\n",
    "    director TEXT DEFAULT NULL,\n",
    "    FOREIGN KEY(show_id) REFERENCES disney_movie(show_id)\n",
    ") STRICT\"\"\"\n",
    "\n",
    "create_movie_cast_stmt = \"\"\"CREATE TABLE IF NOT EXISTS movie_person (\n",
    "    show_id INTEGER,\n",
    "    person TEXT DEFAULT NULL,\n",
    "    FOREIGN KEY(show_id) REFERENCES disney_movie(show_id)\n",
    ") STRICT\"\"\"\n",
    "\n",
    "create_movie_listed_in_stmt = \"\"\"CREATE TABLE IF NOT EXISTS movie_category (\n",
    "    show_id INTEGER,\n",
    "    category TEXT DEFAULT NULL,\n",
    "    FOREIGN KEY(show_id) REFERENCES disney_movie(show_id)\n",
    ") STRICT\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "84319b94-76f5-48d1-bb9a-960ae9cf09cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TV Tables\n",
    "create_tv_stmt = \"\"\"CREATE TABLE IF NOT EXISTS disney_tv (\n",
    "\tshow_id INTEGER PRIMARY KEY,\n",
    "   \ttype TEXT DEFAULT NULL,\n",
    "\ttitle TEXT DEFAULT NULL,\n",
    "\tdate_added TEXT DEFAULT NULL,\n",
    "\trelease_year INTEGER DEFAULT NULL,\n",
    "\trating TEXT DEFAULT NULL, \n",
    "\tnum_seasons INTEGER DEFAULT NULL,\n",
    "\tdescription TEXT DEFAULT NULL\n",
    ") STRICT\"\"\"\n",
    "\n",
    "create_tv_country_stmt = \"\"\"CREATE TABLE IF NOT EXISTS tv_country (\n",
    "    show_id INTEGER,\n",
    "    country TEXT DEFAULT NULL,\n",
    "    FOREIGN KEY(show_id) REFERENCES disney_tv(show_id)\n",
    ") STRICT\"\"\"\n",
    "\n",
    "create_tv_directors_stmt = \"\"\"CREATE TABLE IF NOT EXISTS tv_director (\n",
    "    show_id INTEGER,\n",
    "    director TEXT DEFAULT NULL,\n",
    "    FOREIGN KEY(show_id) REFERENCES disney_tv(show_id)\n",
    ") STRICT\"\"\"\n",
    "\n",
    "create_tv_cast_stmt = \"\"\"CREATE TABLE IF NOT EXISTS tv_person (\n",
    "    show_id INTEGER,\n",
    "    person TEXT DEFAULT NULL,\n",
    "    FOREIGN KEY(show_id) REFERENCES disney_tv(show_id)\n",
    ") STRICT\"\"\"\n",
    "\n",
    "create_tv_listed_in_stmt = \"\"\"CREATE TABLE IF NOT EXISTS tv_category (\n",
    "    show_id INTEGER,\n",
    "    category TEXT DEFAULT NULL,\n",
    "    FOREIGN KEY(show_id) REFERENCES disney_tv(show_id)\n",
    ") STRICT\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0cc36ce0-55b2-4cad-b4fd-5d7082e85da5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlite3.Cursor at 0x10378f040>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cur.execute(create_movies_stmt)\n",
    "cur.execute(create_movie_country_stmt)\n",
    "cur.execute(create_movie_directors_stmt)\n",
    "cur.execute(create_movie_cast_stmt)\n",
    "cur.execute(create_movie_listed_in_stmt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "94ebd77c-c866-4496-8680-ee3563c4c31c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlite3.Cursor at 0x10378f040>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cur.execute(create_tv_stmt)\n",
    "cur.execute(create_tv_country_stmt)\n",
    "cur.execute(create_tv_directors_stmt)\n",
    "cur.execute(create_tv_cast_stmt)\n",
    "cur.execute(create_tv_listed_in_stmt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0a6bc8-0691-4ecc-b1b0-68ec89aedf24",
   "metadata": {},
   "source": [
    "# Step 2: Preprocess Data for Database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0653f466-bc50-4527-8ad4-efbe449c0bdf",
   "metadata": {},
   "source": [
    "## 2.1 Preprocess Fields"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a078e76f-79a5-4f66-8f85-81f8bc6000ec",
   "metadata": {},
   "source": [
    "In order to get the data ready, all of the strings in the original dataset are converted to their respective datatypes and the list-based fields are exploded into a one-to-many relationship. We also strip all of the fields in case there are leading or trailing spaces since those are not typically included on purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f72a694e-d02f-4ee7-93b6-6d4c1fc10211",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_duration(duration_str):\n",
    "    elements = duration_str.split(\" \")\n",
    "\n",
    "    unit = elements[1].lower()\n",
    "    if unit != \"min\" and unit != \"seasons\" and unit != \"season\":\n",
    "        return None\n",
    "    else:\n",
    "        return int(elements[0])\n",
    "\n",
    "def col_to_list(list_str):\n",
    "    if list_str == None:\n",
    "        return None\n",
    "    \n",
    "    elems = list_str.split(\",\")\n",
    "    return [elem.strip() for elem in elems]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "26a97fca-739c-4b7e-b172-04478198b6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "disney_df  = raw_disney_df.copy()\n",
    "\n",
    "# Strip out trailing or leading whitespace\n",
    "for col in disney_df.columns:\n",
    "    disney_df[col] = disney_df[col].map(lambda x: x.strip() if isinstance(x, str) else x)\n",
    "\n",
    "# Change Datatypes\n",
    "disney_df['show_id'] = disney_df.index\n",
    "disney_df['date_added'] = disney_df['date_added'].astype('datetime64[ns]')\n",
    "disney_df['release_year'] = disney_df['release_year'].astype('int64')\n",
    "disney_df['duration'] = disney_df['duration'].map(get_duration)\n",
    "\n",
    "# Make dates human-readable\n",
    "disney_df['date_added'] = disney_df['date_added'].map(lambda dt: None if pd.isnull(dt) else dt.strftime(\"%Y-%m-%d\"))\n",
    "\n",
    "# Use None instead of NaN and NaT\n",
    "for col in disney_df.columns:\n",
    "    disney_df[col] = disney_df[col].map(lambda x: None if pd.isnull(x) else x)\n",
    "\n",
    "# Create lists for columns that are lists\n",
    "disney_df['country'] = disney_df['country'].map(col_to_list)\n",
    "disney_df['director'] = disney_df['director'].map(col_to_list)\n",
    "disney_df['cast'] = disney_df['cast'].map(col_to_list)\n",
    "disney_df['listed_in'] = disney_df['listed_in'].map(col_to_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a40f3909-d9d9-49dd-a757-137a3dc87aff",
   "metadata": {},
   "source": [
    "## 2.2 Preprocessing Considerations:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcba1b35-abbe-4ff1-ba2b-5758744b786f",
   "metadata": {},
   "source": [
    "For this dataset, null values are not a big issue as there is no practical impact of having values be null. However, we will assume certain things for this dataset. We will check for null values and for values out of range. For demonstration purposes, we will default null-values in the country field to be for the United States and will assume the release year to be between 1950 and today. If there are any past today's date, we will assume it is for this year. \n",
    "\n",
    "For other datasets, null values may have a negative impact on downstream usage of the database. Null values and data issues will need more investigation since the data may not be missing at random. Based on the upstream reasons for null values and the downstream affects, we may want to forwardfill, backfill, impute, or leave as null. \n",
    "\n",
    "For example, perhaps the release years past today are mistakes, or perhaps there is a common mistake that we can find. Maybe 2081 really means 2018 and there was manual entry error where an individual swapped the 1 and 8; in this case, it would not be approprate to assume the current year as we are assuming now. There are also other fields that could have data entry issues, commonly names are spelled wrong in datasets, and we can use text similarity to predict if two names are really the same person. Similarly, there could be a consistency issue such as J. Smith being ths ame person as John Smith; this is not always the case but for some datasets, we may be able to make this assumption if a last name is very unique or if the data set is limited to a known set of fields.\n",
    "\n",
    "We may also consider removing non-ASCII characters too, however, that is not an issue with this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6545622f-1be4-4e0a-b54a-3d3a168514fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clean_release_year(title_year):\n",
    "    current_year = datetime.date.today().year\n",
    "\n",
    "    if pd.isnull(title_year):\n",
    "        return None\n",
    "    else:\n",
    "        return max(min(current_year, title_year), 1950)\n",
    "\n",
    "disney_df['country'] = disney_df['country'].fillna('United States')\n",
    "disney_df['release_year'] = disney_df['release_year'].map(get_clean_release_year) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ca39a4d1-bac5-4989-98bf-d04379edbc6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the dataframe after preprocessing\n",
    "movies_df = disney_df[disney_df['type'] == 'Movie']\n",
    "tv_df = disney_df[disney_df['type'] == 'TV Show']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c20d8873-1810-4a16-98d7-6c55d83b1415",
   "metadata": {},
   "source": [
    "## 2.3 Populate Database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23439990-d82c-485a-af97-3b6c4e2b57dd",
   "metadata": {},
   "source": [
    "The following functions then populate the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "041019b1-0cff-4320-b54d-1a58f73a7317",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_row(row):\n",
    "    def clean_elem(elem):\n",
    "        cleaned_elem = str(elem) if not pd.isnull(elem) else elem\n",
    "        return cleaned_elem\n",
    "    return [clean_elem(elem) for elem in row]\n",
    "\n",
    "\n",
    "def create_sql_insert_list(values_df):\n",
    "    cleaned_values = [clean_row(row) for row in values_df]\n",
    "    return cleaned_values\n",
    "\n",
    "def populate_table(con, cursor, tablename, df):\n",
    "    num_values = len(df.columns)\n",
    "    placeholder_str = \", \".join([\"?\"]*num_values)\n",
    "    values_list = create_sql_insert_list(df.values.tolist())   \n",
    "    cursor.executemany(f\"INSERT INTO {tablename} VALUES ({placeholder_str})\", values_list)\n",
    "    con.commit()\n",
    "    \n",
    "def populate_all_tables(con, cursor, df, label):\n",
    "    titles_df = df[['show_id', 'type', 'title', 'date_added', 'release_year', 'rating', 'duration', 'description']]\n",
    "    country_df = df[['show_id','country']].dropna(subset='country')\n",
    "    directors_df = df[['show_id','director']].dropna(subset='director')\n",
    "    cast_df = df[['show_id', 'cast']].dropna(subset='cast')\n",
    "    category_df = df[['show_id', 'listed_in']].dropna(subset='listed_in')\n",
    "\n",
    "    populate_table(con, cursor, f'disney_{label}', titles_df)\n",
    "\n",
    "    populate_table(con, cursor, f'{label}_country', country_df.explode('country'))\n",
    "    populate_table(con, cursor, f'{label}_director', directors_df.explode('director'))\n",
    "    populate_table(con, cursor, f'{label}_person', cast_df.explode('cast'))\n",
    "    populate_table(con, cursor, f'{label}_category', category_df.explode('listed_in'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "92329897-13a1-4245-a417-d03ddb8c6d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "populate_all_tables(con, cur, movies_df, 'movie')\n",
    "populate_all_tables(con, cur, tv_df, 'tv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "530a1f77-f31c-431a-abd5-818d3ce7e4d8",
   "metadata": {},
   "source": [
    "## 2.4 Retrive Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b0830ac-9462-4370-8975-f08731518ff8",
   "metadata": {},
   "source": [
    "Below are examples of how one may query the database for the data. The \"get_all_titles\" function provides functionality to return all titles similar to the original dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "93c5ff70-ff8b-4e7e-861a-209a2b07a7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute a SELECT query\n",
    "cur.execute(\"\"\"SELECT * FROM disney_movie\"\"\")\n",
    "column_names = [description[0] for description in cur.description]\n",
    "disney_movie_df = pd.DataFrame(cur.fetchall(), columns=column_names)\n",
    "\n",
    "cur.execute(\"SELECT * FROM movie_director\")\n",
    "column_names = [description[0] for description in cur.description]\n",
    "movie_director_df = pd.DataFrame(cur.fetchall(), columns=column_names)\n",
    "\n",
    "cur.execute(\"SELECT * FROM movie_person\")\n",
    "column_names = [description[0] for description in cur.description]\n",
    "movie_person_df = pd.DataFrame(cur.fetchall(), columns=column_names)\n",
    "\n",
    "cur.execute(\"SELECT * FROM disney_tv\")\n",
    "column_names = [description[0] for description in cur.description]\n",
    "disney_tv_df = pd.DataFrame(cur.fetchall(), columns=column_names)\n",
    "\n",
    "cur.execute(\"SELECT * FROM tv_director\")\n",
    "column_names = [description[0] for description in cur.description]\n",
    "tv_director_df = pd.DataFrame(cur.fetchall(), columns=column_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf29c88e-3508-4dd5-9b10-b18e0702aa7c",
   "metadata": {},
   "source": [
    "From the above, an analyst could join on these tables and do basic statistics and filter the data based on country, director, etc. The analyst may also analyze the data to see which categories of content produce the highest ratings. With some NLP techniques, a data scientist may also be able to predict the ratings of any new titles that Disney is planning on releasing based on the categories, descriptions, and titles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "616ce1db-265e-4f3a-81f8-68f7e12c1528",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_titles(cursor, label):\n",
    "    cursor.execute(f\"\"\"\n",
    "        SELECT disney_{label}.*, \n",
    "            GROUP_CONCAT(director, ', ') AS directors, \n",
    "            GROUP_CONCAT(person, ', ') AS cast, \n",
    "            GROUP_CONCAT(category, ', ') AS listed_in\n",
    "        FROM disney_{label}\n",
    "        LEFT JOIN {label}_director ON disney_{label}.show_id = {label}_director.show_id\n",
    "        LEFT JOIN {label}_person ON disney_{label}.show_id = {label}_person.show_id\n",
    "        LEFT JOIN {label}_category ON disney_{label}.show_id = {label}_category.show_id\n",
    "        GROUP BY disney_{label}.show_id\n",
    "        ORDER BY disney_{label}.show_id asc\n",
    "        \"\"\")\n",
    "    column_names = [description[0] for description in cur.description]\n",
    "    res_df = pd.DataFrame(cur.fetchall(), columns=column_names)\n",
    "    return res_df\n",
    "\n",
    "def get_all_titles(cursor):\n",
    "    tv_titles_df = get_titles(cursor, 'tv')\n",
    "    movie_titles_df = get_titles(cursor, 'movie')\n",
    "    return pd.concat([tv_titles_df, movie_titles_df])\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "178ea63b-7807-4fe2-9461-78a89b71e707",
   "metadata": {},
   "outputs": [],
   "source": [
    "disney_titles_df = get_all_titles(cur)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe328192-d965-480f-918c-31f1fc5bcb6c",
   "metadata": {},
   "source": [
    "Creating a similar structure to the original dataset is useful, however, joining in this way makes it more difficult to trend on the list-based fields."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b588e329-04dd-48c2-8771-5b03dc3a0de7",
   "metadata": {},
   "source": [
    "# Step 3: Vectorization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9efad11-f60e-4e2e-a6c0-a9f5a32a83d1",
   "metadata": {},
   "source": [
    "We will use Huggingface for Embeddings and Milvus for the Vector database as they are open-source, and actively being developed. A vector database allows us to provide quick vector similarity search and is a scalable solution as the number of documents stored and vectorized becomes larger. The descriptions hold the most information, so we will want be storing this information into the vector database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "20fa9c3a-8b0e-4c87-8d28-8a785ccb5625",
   "metadata": {},
   "outputs": [],
   "source": [
    "milvus_client = MilvusClient(\"./milvus_disney.db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "eabcfcc0-1592-4c76-afde-b641f3ec8137",
   "metadata": {},
   "outputs": [],
   "source": [
    "milvus_client.create_collection(\n",
    "    collection_name=\"disney_collection\",\n",
    "    dimension=384\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0fe524d7-6c4c-4468-b2bc-81cb0f9ec7a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brandonlam/anaconda3/envs/disney/lib/python3.12/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:13: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "embeddings = HuggingFaceEmbeddings(model_name=\"paraphrase-MiniLM-L3-v2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b477403a-159d-4287-8363-4fa1962697e2",
   "metadata": {},
   "source": [
    "For documents with larger texts, we will chunk each of the documents. There are several ways to do this such as Fixed Size Chunking, Recursive Chunking, Document Chunking, etc. Here we will use recursive chunking where we are chunking based on a space with a max chunk size of 100. The generator should help with memory for larger texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f4c24763-17fd-4d68-8ae0-922dbf88e40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHUNK_SIZE = 100\n",
    "\n",
    "# Generator that creates chunks based on the max_chunk size, splitting by \" \"\n",
    "def get_chunks(s, max_chunk_size=CHUNK_SIZE):\n",
    "    start = 0\n",
    "    end = 0\n",
    "    while start + max_chunk_size  < len(s) and end != -1: # Loop and find all words that fit in the chunk\n",
    "        end = s.rfind(\" \", start, start + max_chunk_size + 1)\n",
    "        yield s[start:end]\n",
    "        start = end + 1\n",
    "    yield s[start:] # The remaining words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37de1923-d562-48c8-9590-b1f356047222",
   "metadata": {},
   "source": [
    "Here we are going to insert into the Milvus vector database using a batch size of 500. This dataset isn't too big, but batch updating can help for larger datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ae714151-9d3d-4390-97e0-e0c310ff49b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 500\n",
    "\n",
    "collection_data = []\n",
    "for i, row in disney_titles_df.iterrows():\n",
    "    description = row['description']\n",
    "    for chunk in get_chunks(description):\n",
    "        chunk_vector = embeddings.embed_query(chunk)\n",
    "        collection_element = {\"id\": i, \n",
    "              \"vector\": chunk_vector, \n",
    "              \"text\": chunk, \n",
    "              \"type\": row['type'],\n",
    "              \"rating\": row['rating'],\n",
    "              \"num_seasons\": row['num_seasons'],\n",
    "              \"duration\": row['duration_min'],\n",
    "        }\n",
    "        collection_data.append(collection_element)\n",
    "\n",
    "        # Insert embedding data into Milvus when batch size hit\n",
    "        if len(collection_data) % BATCH_SIZE == 0:\n",
    "            res = milvus_client.insert(\n",
    "                collection_name=\"disney_collection\",\n",
    "                data=collection_data\n",
    "            )\n",
    "            collection_data = []\n",
    "\n",
    "# Insert remaining embedding data into Milvus\n",
    "res = milvus_client.insert(\n",
    "    collection_name=\"disney_collection\",\n",
    "    data=collection_data\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca17ab9-187e-4533-9b0f-fcc4e576ac2b",
   "metadata": {},
   "source": [
    "We did not do so here, but creating multiple partitions may make search even faster and improve query performance as it can limit the search field if specifying a partition. For example, we could partition based on movie vs. tv show or partition baased on country. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6fd9e35-062e-4620-a168-8ce5685a0813",
   "metadata": {},
   "source": [
    "# Step 4: Query and Retrieve"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dfa570c-24fa-4a7f-9895-49c98e904d0b",
   "metadata": {},
   "source": [
    "After adding the embeddings to the collection, we can then search effectively and help generate relevant context for an LLM. Below you can see how this could work in practice. Say we want to know who the Avengers are, we can use the Milvus client to search and return the top 10 embeddings regarding the Avengers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "416d1e6e-bdaa-4744-b48a-2772020eadcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Who are the Avengers?\"\n",
    "query_embedding = embeddings.embed_query(query)\n",
    "\n",
    "\n",
    "res = milvus_client.search(\n",
    "    collection_name=\"disney_collection\", # Replace with the actual name of your collection\n",
    "    data=[query_embedding],\n",
    "    limit=10, # Max. number of search results to return\n",
    "    output_fields=['text']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6d7293d8-03d6-40ad-abe7-c2454eb654e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A new team of heroes joins the Avengers.',\n",
       " 'The Avengers must be willing to sacrifice all to defeat Thanos.',\n",
       " 'Captain America and Iron Man clash, causing the Avengers to choose sides.',\n",
       " 'The epic finale to the Infinity Saga, this dramatic showdown pits the Avengers against Thanos.',\n",
       " 'Avengers Iron Man and Hulk team up to fight an energy-devouring monster.',\n",
       " 'The greatest heroes on the planet unite to face the greatest villains in the Super Hero Squad.',\n",
       " 'Marvel’s mightiest heroes combine their power.',\n",
       " 'Marvel Studios’ Captain Marvel launches the MCU’s most powerful hero.',\n",
       " 'The teenage son in a superhero family anxiously awaits his super powers.',\n",
       " 'Marvel’s young powered heroes join forces to protect the Universe.']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_results = [elem['entity']['text'] for elem in res[0]]\n",
    "search_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b74322-c5de-4736-8027-e3934258b020",
   "metadata": {},
   "source": [
    "From the above search query, we can see that the search results correctly found movie and tv descriptions mentioning the Avengers and Marvel. In a RAG system, this will provide a narrower context to the LLM, allowing it to more quickly and accurately create a response to  the original query \"Who are the Avengers?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34178f95-60e5-4b0f-b566-6feb69dbcbf6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
